[
  {
    "objectID": "source/s3/memo.html",
    "href": "source/s3/memo.html",
    "title": "Se connecter √† S3",
    "section": "",
    "text": "Pour configurer sa connection √† s3, des variables d‚Äôenvironnement et fichiers de configuration sont reconnus par la plupart des librairies. Ainsi, si seul un endpoint est utilis√©, on pourra souvent se contenter d‚Äôutiliser des variables d‚Äôenvironnement (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_DEFAULT_REGION, ENDPOINT_URL). Au del√† d‚Äôun endpoint, et afin de gagner en flexibilit√©, il est possible de cr√©er des fichiers de configuration situ√©s √† la racine du r√©pertoire utilisateur ($HOME). Les fichiers sont d√©coup√©s en profiles permettant de configurer diff√©rents param√®tres et credentials. Le fichier .aws/config permet de d√©finir les endpoints d‚Äôint√©r√™t, tandis que le fichier .aws/credentials sert √† stocker les credentials associ√©s. Par d√©faut, s‚Äôil existe, le profil default sera utilis√©.\n.aws/config\n[default]\nregion = us-east-1\nendpoint_url = https://my-minio\n\n[profile test]\nregion = us-east-1\nendpoint_url = https://my-minio2\n\n.aws/credentials\n[default]\naws_access_key_id = default_access_key\naws_secret_access_key = default_secret_access_key\naws_session_token = default_token\n\n[test]\naws_access_key_id = test_access_key\naws_secret_access_key = test_secret_acess_key\n\n\nimport s3fs\n\nfs = s3fs.S3FileSystem(\n    client_kwargs={'endpoint_url': ENDPOINT_URL},\n    key = AWS_ACCESS_KEY_ID, \n    secret = AWS_SECRET_ACCESS_KEY, \n    token = AWS_SESSION_TOKEN\"),\n\nAvec des fichiers de config\nimport s3fs\n\nfs = s3fs.S3FileSystem()\nfiles = fs.ls('inesh')\nprint(files)\nSi on veut changer de profil\nimport s3fs\n\nfs = s3fs.S3FileSystem(profile=\"toto\")\nfiles = fs.ls('inesh')\nprint(files)\n\n\n\nimport boto3\n\nclient = boto3.client(\n    's3',\n    aws_access_key_id=ACCESS_KEY,\n    aws_secret_access_key=SECRET_KEY,\n    aws_session_token=SESSION_TOKEN,\n    endpoint_url=ENDPOINT_URL,\n)\nAvec des fichiers de config,\nimport boto3\nclient = boto3.client('s3)\n\nresponse = client.list_objects_v2(Bucket='inesh')\nprint(response)\n\nSi on veut changer de profil\nimport boto3\n\nsession = boto3.Session(profile_name='toto')\ns3_client = session.client(service_name='s3')\n\n\n\n\nPour configurer mc : une variable d‚Äôenvironnement suffit : MC_HOST_ALIAS = ‚Äúhttps://::@‚Äù exemple:\nexport MC_HOST_s3 = \"https://$AWS_ACCESS_KEY_ID$:AWS_SECRET_ACCESS_KEY:AWS_SESSION_TOKEN@$ENDPOINT_URL$\"\nUne fois le tout configur√©, nous pouvons lister le contenu de notre bucket\nmc ls s3/my-bucket\ncopier un fichier\nmc cp s3/my-bucket/my-file.txt s3/my-bucket/somewhere-else/my-file.txt\nle t√©l√©charger\nmc get s3/my-bucket/my-file.txt ./data/my-file.txt\nle supprimer\nmc rm s3/my-bucket/my-file.txt\nl‚Äôuploader\nmc cp ./data/my-file.txt s3/my-bucket/my-second-file.txt",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/memo.html#en-utilisant-s3fs",
    "href": "source/s3/memo.html#en-utilisant-s3fs",
    "title": "Se connecter √† S3",
    "section": "",
    "text": "import s3fs\n\nfs = s3fs.S3FileSystem(\n    client_kwargs={'endpoint_url': ENDPOINT_URL},\n    key = AWS_ACCESS_KEY_ID, \n    secret = AWS_SECRET_ACCESS_KEY, \n    token = AWS_SESSION_TOKEN\"),\n\nAvec des fichiers de config\nimport s3fs\n\nfs = s3fs.S3FileSystem()\nfiles = fs.ls('inesh')\nprint(files)\nSi on veut changer de profil\nimport s3fs\n\nfs = s3fs.S3FileSystem(profile=\"toto\")\nfiles = fs.ls('inesh')\nprint(files)",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/memo.html#en-utilisant-boto3",
    "href": "source/s3/memo.html#en-utilisant-boto3",
    "title": "Se connecter √† S3",
    "section": "",
    "text": "import boto3\n\nclient = boto3.client(\n    's3',\n    aws_access_key_id=ACCESS_KEY,\n    aws_secret_access_key=SECRET_KEY,\n    aws_session_token=SESSION_TOKEN,\n    endpoint_url=ENDPOINT_URL,\n)\nAvec des fichiers de config,\nimport boto3\nclient = boto3.client('s3)\n\nresponse = client.list_objects_v2(Bucket='inesh')\nprint(response)\n\nSi on veut changer de profil\nimport boto3\n\nsession = boto3.Session(profile_name='toto')\ns3_client = session.client(service_name='s3')",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/memo.html#en-utilisant-mc-cli",
    "href": "source/s3/memo.html#en-utilisant-mc-cli",
    "title": "Se connecter √† S3",
    "section": "",
    "text": "Pour configurer mc : une variable d‚Äôenvironnement suffit : MC_HOST_ALIAS = ‚Äúhttps://::@‚Äù exemple:\nexport MC_HOST_s3 = \"https://$AWS_ACCESS_KEY_ID$:AWS_SECRET_ACCESS_KEY:AWS_SESSION_TOKEN@$ENDPOINT_URL$\"\nUne fois le tout configur√©, nous pouvons lister le contenu de notre bucket\nmc ls s3/my-bucket\ncopier un fichier\nmc cp s3/my-bucket/my-file.txt s3/my-bucket/somewhere-else/my-file.txt\nle t√©l√©charger\nmc get s3/my-bucket/my-file.txt ./data/my-file.txt\nle supprimer\nmc rm s3/my-bucket/my-file.txt\nl‚Äôuploader\nmc cp ./data/my-file.txt s3/my-bucket/my-second-file.txt",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html",
    "href": "source/s3/cestquoi.html",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "S3 est un protocole de stockage objet d√©riv√© du service initialement offert par le cloud provider AWS.\n\n\nPour comprendre l‚Äôint√©r√™t du stockage objet il faut d‚Äôabord identifier les limites des solutions de stockage historiques.\nHistoriquement, les offres principales de stockage disponibles dans les infrastructures informatiques sont des offres dites block storage ou file storage. M√™me s‚Äôil existe des diff√©rences et tout un tas d‚Äôimpl√©mentations diff√©rentes de ces deux syst√®mes, le r√©sultat pour un d√©veloppeur ou un statisticien est souvent le m√™me : un partage r√©seau mont√© directement sur ses environnements d‚Äôex√©cution (poste de travail, serveur distant ‚Ä¶).\nLes limites de ces syst√®mes sont multiples :\n\nIls constituent un frein majeur √† la portabilit√© : un process ne pourra s‚Äôex√©cuter que sur un environnement o√π les donn√©es sont mont√©es\n\nIls constituent un frein majeur √† l‚Äôint√©rop√©rabilit√© : ces syst√®mes sont souvent tr√®s adh√©rents √† l‚Äôinfrastructure de donn√©es\nIls constituent un frein majeur √† la scalabilit√© : ces syst√®mes ne sont pas pens√©s pour √™tre mont√©s et utilis√©s par des centaines de process simultan√©ment\n\nIls induisent une charge sur les √©quipes d‚Äôinfra qui doivent pr√©configurer tous les environnements pour y monter les ‚Äúbons‚Äù partages\n\nLe mod√®le de s√©curit√© associ√© est imparfait : pour ces syst√®mes, le contr√¥le d‚Äôacc√®s se fait souvent au moment du montage de la ressource. Une fois la ressource accessible √† l‚Äôenvironnement, les acc√®s unitaires sont plus difficilement tra√ßables, auditables et validables\n\n\n\n\nLe stockage objet apporte des solutions aux probl√©matiques pr√©c√©dentes en inversant l‚Äôapproche.\nAu lieu de rendre disponible les donn√©es en les montant directement dans les environnements, c‚Äôest l‚Äôapplicatif qui va directement requ√™ter les donn√©es au moment de leur utilisation.\n\nLes environnements d‚Äôex√©cution n‚Äôont plus de pr√©requis ce qui offre une flexibilit√©, portabilit√© et int√©rop√©rabilit√© incroyable\nLe mod√®le de s√©curit√© passe √† un contr√¥le d‚Äôacc√®s par requ√™te, beaucoup plus fin, tra√ßable et auditable\nLe syst√®me est nativement scalable\n\n\n\n\nS3 est un protocole impl√©mentant les principes du stockage objet.\nIl est important de faire la distinction entre S3 (le protocole) et AWS S3 (le service S3 h√©berg√© chez AWS).\nIl est donc tout √† fait possible d‚Äôinstaller un serveur compatible S3 chez soi. Citons 2 impl√©mentations : minIO & CEPH.\n\n\n\nS3 expose une API REST HTTP. Toute int√©raction avec un serveur S3 passe par des requ√™tes HTTP que √ßa soit pour t√©l√©charger, uploader ou supprimer des donn√©es ou m√™me pour le configurer.\nComme pour toute API, la premi√®re √©tape pour discuter avec est d‚Äôobtenir son URL.\nPar exemple:\n\nAWS S3 : http://s3.amazonaws.com/ - qui est tr√®s souvent configur√© par d√©faut, autant pour les librairies que pour les clients.\nSSP CLOUD : https://minio.lab.sspcloud.fr\nLS3 : https://minio.datascience.kube.insee.fr\npour un usage interne : https://minio.dev.kube.insee.fr ‚Ä¶\n\n\n\n\nSans le savoir vous faites d√©j√† des tonnes de requ√™tes vers des serveurs S3 tout les jours.\nPar exemple, ce chat vous est offert par un serveur S3 : \nCette image est disponible directement √† l‚ÄôURL https://minio.lab.sspcloud.fr/f2wbnp/public/chat.jpg\nPour les fichiers publics, le t√©l√©chargement se fait simplement via une requ√™te GET classique.\nL‚Äôobjet poss√®de une URL compos√©e de :\n\nURL de base du serveur S3 : https://minio.lab.sspcloud.fr\n\nNom du bucket : f2wbnp (√† noter que pour la plupart des serveurs S3, l‚Äôacc√®s est aussi possible via un sous-domaine correspondant au bucket : https://f2wbnp.minio.lab.sspcloud.fr/public/chat.jpg , on parle alors de virtual host style access plut√¥t que path style access)\n\nChemin de l‚Äôobjet au sein du bucket : public/chat.jpg\n\nUn bucket correspond en gros √† un dossier √† la racine du serveur S3. Les buckets permettent de s√©parer les usages, les permissions, les quotas ‚Ä¶\nEn fonction du serveur S3 que vous utilisez et des permissions que vous avez, vous pouvez avoir acc√®s √† tout ou partie d‚Äôun ou plusieurs buckets.\n\n\nA part pour l‚Äôacc√®s aux donn√©es explicitement rendues publiques (la gestion de la visibilit√© et des permissions sur les fichiers se fait en g√©n√©ral via un syst√®me de policies qui n‚Äôest pas abord√© dans cette pr√©sentation), il faudra des informations d‚Äôauthentification (credentials) pour communiquer avec l‚ÄôAPI.\nCes credentials sont constitu√©s d‚Äôun duo access key & secret key (en gros login / mot de passe) pour les comptes de service et d‚Äôun trio access key, secret key, session token pour les identit√©s temporaires (credentials personnels, expirant au bout d‚Äôun certain temps).\nPourront √™tre utilis√©es les variables d‚Äôenvironnements suivantes, g√©n√©ralement reconnues par les biblioth√®ques standards S3 :\nAWS_ACCESS_KEY_ID=my_access_key AWS_SECRET_ACCESS_KEY=my_secret_key AWS_SESSION_TOKEN = my_session_token ENDPOINT_URL = s3_endpoint\nPour r√©cup√©rer vos credentials, vous pouvez vous rendre sur - LS3 / SSPCLOUD : onglet my account &gt; Connect to storage et s√©lectionner shell environment variable\n\n\n\n\nAfin de simplifier les int√©ractions avec l‚ÄôAPI S3, nous allons utiliser un client s3. Cela permettra de g√©rer l‚Äôauthentification et de construire les requ√™tes HTTP correspondant √† vos commandes.\nDes exemples de clients s3 en ligne de commande :\n\nmc (minIO Client) : compatible pour tout service compatible s3\ns3cmd : compatible pour tout service compatible s3\n\naws cli : outil officiel pour int√©ragir avec Amazon S3\nrclone : couteau suisse multicloud, supporte d‚Äôautres protocoles que S3\n\nIl existe √©videmment des interfaces graphiques ainsi que des biblioth√®ques (SDK) pour tous les langages.\nVous √™tes √©videmment libres d‚Äôutiliser le client S3 de votre choix, en fonction de vos pr√©f√©rences.\nDans la suite on illustrera √† partir du client mc mais vous √™tes encourag√©s √† tester diff√©rents clients.\nDans tous les cas, client + URL + credentials = √ßa marche :)\n\n\n\nS3 (et plus g√©n√©ralement le stockage objet) est parfait pour un certain nombre d‚Äôusages mais pas tous.\nLes principales limitations sont les suivantes :\n\nL‚Äô√©criture partielle n‚Äôest pas possible : un fichier ne peut pas √™tre modifi√©. La moindre modification (y compris renommage) correspond √† la r√©√©criture compl√®te du fichier\n\nLa latence est plus forte que pour un stockage block / fichiers classique : il n‚Äôest donc pas adapt√© pour des syst√®mes ayant besoin d‚Äôune latence faible comme les bases de donn√©es relationnelles\n\nDu coup on en tire quelques le√ßons :\n\nWrite once, read many : S3 est particuli√®rement adapt√© √† ce pattern. Parfait pour les backups, les logs, les ressources statiques, la diffusion des repertoires\nS3 n‚Äôa pas vocation √† remplacer enti√®rement les stockages block / fichiers existants mais √† venir en compl√©ment pour les bons cas d‚Äôusage\n\n\n\n\nhttps://docs.sspcloud.fr/content/storage.html",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#les-limites-des-offres-de-stockage-historiques",
    "href": "source/s3/cestquoi.html#les-limites-des-offres-de-stockage-historiques",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "Pour comprendre l‚Äôint√©r√™t du stockage objet il faut d‚Äôabord identifier les limites des solutions de stockage historiques.\nHistoriquement, les offres principales de stockage disponibles dans les infrastructures informatiques sont des offres dites block storage ou file storage. M√™me s‚Äôil existe des diff√©rences et tout un tas d‚Äôimpl√©mentations diff√©rentes de ces deux syst√®mes, le r√©sultat pour un d√©veloppeur ou un statisticien est souvent le m√™me : un partage r√©seau mont√© directement sur ses environnements d‚Äôex√©cution (poste de travail, serveur distant ‚Ä¶).\nLes limites de ces syst√®mes sont multiples :\n\nIls constituent un frein majeur √† la portabilit√© : un process ne pourra s‚Äôex√©cuter que sur un environnement o√π les donn√©es sont mont√©es\n\nIls constituent un frein majeur √† l‚Äôint√©rop√©rabilit√© : ces syst√®mes sont souvent tr√®s adh√©rents √† l‚Äôinfrastructure de donn√©es\nIls constituent un frein majeur √† la scalabilit√© : ces syst√®mes ne sont pas pens√©s pour √™tre mont√©s et utilis√©s par des centaines de process simultan√©ment\n\nIls induisent une charge sur les √©quipes d‚Äôinfra qui doivent pr√©configurer tous les environnements pour y monter les ‚Äúbons‚Äù partages\n\nLe mod√®le de s√©curit√© associ√© est imparfait : pour ces syst√®mes, le contr√¥le d‚Äôacc√®s se fait souvent au moment du montage de la ressource. Une fois la ressource accessible √† l‚Äôenvironnement, les acc√®s unitaires sont plus difficilement tra√ßables, auditables et validables",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#le-stockage-objet",
    "href": "source/s3/cestquoi.html#le-stockage-objet",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "Le stockage objet apporte des solutions aux probl√©matiques pr√©c√©dentes en inversant l‚Äôapproche.\nAu lieu de rendre disponible les donn√©es en les montant directement dans les environnements, c‚Äôest l‚Äôapplicatif qui va directement requ√™ter les donn√©es au moment de leur utilisation.\n\nLes environnements d‚Äôex√©cution n‚Äôont plus de pr√©requis ce qui offre une flexibilit√©, portabilit√© et int√©rop√©rabilit√© incroyable\nLe mod√®le de s√©curit√© passe √† un contr√¥le d‚Äôacc√®s par requ√™te, beaucoup plus fin, tra√ßable et auditable\nLe syst√®me est nativement scalable",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#s3",
    "href": "source/s3/cestquoi.html#s3",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "S3 est un protocole impl√©mentant les principes du stockage objet.\nIl est important de faire la distinction entre S3 (le protocole) et AWS S3 (le service S3 h√©berg√© chez AWS).\nIl est donc tout √† fait possible d‚Äôinstaller un serveur compatible S3 chez soi. Citons 2 impl√©mentations : minIO & CEPH.",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#s3-une-api-http",
    "href": "source/s3/cestquoi.html#s3-une-api-http",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "S3 expose une API REST HTTP. Toute int√©raction avec un serveur S3 passe par des requ√™tes HTTP que √ßa soit pour t√©l√©charger, uploader ou supprimer des donn√©es ou m√™me pour le configurer.\nComme pour toute API, la premi√®re √©tape pour discuter avec est d‚Äôobtenir son URL.\nPar exemple:\n\nAWS S3 : http://s3.amazonaws.com/ - qui est tr√®s souvent configur√© par d√©faut, autant pour les librairies que pour les clients.\nSSP CLOUD : https://minio.lab.sspcloud.fr\nLS3 : https://minio.datascience.kube.insee.fr\npour un usage interne : https://minio.dev.kube.insee.fr ‚Ä¶",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#premier-contact",
    "href": "source/s3/cestquoi.html#premier-contact",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "Sans le savoir vous faites d√©j√† des tonnes de requ√™tes vers des serveurs S3 tout les jours.\nPar exemple, ce chat vous est offert par un serveur S3 : \nCette image est disponible directement √† l‚ÄôURL https://minio.lab.sspcloud.fr/f2wbnp/public/chat.jpg\nPour les fichiers publics, le t√©l√©chargement se fait simplement via une requ√™te GET classique.\nL‚Äôobjet poss√®de une URL compos√©e de :\n\nURL de base du serveur S3 : https://minio.lab.sspcloud.fr\n\nNom du bucket : f2wbnp (√† noter que pour la plupart des serveurs S3, l‚Äôacc√®s est aussi possible via un sous-domaine correspondant au bucket : https://f2wbnp.minio.lab.sspcloud.fr/public/chat.jpg , on parle alors de virtual host style access plut√¥t que path style access)\n\nChemin de l‚Äôobjet au sein du bucket : public/chat.jpg\n\nUn bucket correspond en gros √† un dossier √† la racine du serveur S3. Les buckets permettent de s√©parer les usages, les permissions, les quotas ‚Ä¶\nEn fonction du serveur S3 que vous utilisez et des permissions que vous avez, vous pouvez avoir acc√®s √† tout ou partie d‚Äôun ou plusieurs buckets.\n\n\nA part pour l‚Äôacc√®s aux donn√©es explicitement rendues publiques (la gestion de la visibilit√© et des permissions sur les fichiers se fait en g√©n√©ral via un syst√®me de policies qui n‚Äôest pas abord√© dans cette pr√©sentation), il faudra des informations d‚Äôauthentification (credentials) pour communiquer avec l‚ÄôAPI.\nCes credentials sont constitu√©s d‚Äôun duo access key & secret key (en gros login / mot de passe) pour les comptes de service et d‚Äôun trio access key, secret key, session token pour les identit√©s temporaires (credentials personnels, expirant au bout d‚Äôun certain temps).\nPourront √™tre utilis√©es les variables d‚Äôenvironnements suivantes, g√©n√©ralement reconnues par les biblioth√®ques standards S3 :\nAWS_ACCESS_KEY_ID=my_access_key AWS_SECRET_ACCESS_KEY=my_secret_key AWS_SESSION_TOKEN = my_session_token ENDPOINT_URL = s3_endpoint\nPour r√©cup√©rer vos credentials, vous pouvez vous rendre sur - LS3 / SSPCLOUD : onglet my account &gt; Connect to storage et s√©lectionner shell environment variable",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#un-client-pour-communiquer-avec-s3",
    "href": "source/s3/cestquoi.html#un-client-pour-communiquer-avec-s3",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "Afin de simplifier les int√©ractions avec l‚ÄôAPI S3, nous allons utiliser un client s3. Cela permettra de g√©rer l‚Äôauthentification et de construire les requ√™tes HTTP correspondant √† vos commandes.\nDes exemples de clients s3 en ligne de commande :\n\nmc (minIO Client) : compatible pour tout service compatible s3\ns3cmd : compatible pour tout service compatible s3\n\naws cli : outil officiel pour int√©ragir avec Amazon S3\nrclone : couteau suisse multicloud, supporte d‚Äôautres protocoles que S3\n\nIl existe √©videmment des interfaces graphiques ainsi que des biblioth√®ques (SDK) pour tous les langages.\nVous √™tes √©videmment libres d‚Äôutiliser le client S3 de votre choix, en fonction de vos pr√©f√©rences.\nDans la suite on illustrera √† partir du client mc mais vous √™tes encourag√©s √† tester diff√©rents clients.\nDans tous les cas, client + URL + credentials = √ßa marche :)",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#cas-dusages-et-limites",
    "href": "source/s3/cestquoi.html#cas-dusages-et-limites",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "S3 (et plus g√©n√©ralement le stockage objet) est parfait pour un certain nombre d‚Äôusages mais pas tous.\nLes principales limitations sont les suivantes :\n\nL‚Äô√©criture partielle n‚Äôest pas possible : un fichier ne peut pas √™tre modifi√©. La moindre modification (y compris renommage) correspond √† la r√©√©criture compl√®te du fichier\n\nLa latence est plus forte que pour un stockage block / fichiers classique : il n‚Äôest donc pas adapt√© pour des syst√®mes ayant besoin d‚Äôune latence faible comme les bases de donn√©es relationnelles\n\nDu coup on en tire quelques le√ßons :\n\nWrite once, read many : S3 est particuli√®rement adapt√© √† ce pattern. Parfait pour les backups, les logs, les ressources statiques, la diffusion des repertoires\nS3 n‚Äôa pas vocation √† remplacer enti√®rement les stockages block / fichiers existants mais √† venir en compl√©ment pour les bons cas d‚Äôusage",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#aller-plus-loin",
    "href": "source/s3/cestquoi.html#aller-plus-loin",
    "title": "S3, c‚Äôest quoi ?",
    "section": "",
    "text": "https://docs.sspcloud.fr/content/storage.html",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/parquet/letsgo.html",
    "href": "source/parquet/letsgo.html",
    "title": "Parquet, let‚Äôs go !",
    "section": "",
    "text": "Parquet, let‚Äôs go !\nPour pratiquer du parquet on va utiliser DuckDB mais il est tout √† fait possible d‚Äôexploiter les fichiers parquet directement en utilisant les biblioth√®ques adapt√©es √† votre langage (cf le m√©mo).\nDonn√©es du RP sur data.gouv.fr : https://www.data.gouv.fr/fr/datasets/recensement-de-la-population-fichiers-detail-individus-localises-au-canton-ou-ville/",
    "crumbs": [
      "Parquet",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/memo.html",
    "href": "source/duckdb/memo.html",
    "title": "Memo DuckDB ü¶Ü",
    "section": "",
    "text": "Memo DuckDB ü¶Ü",
    "crumbs": [
      "DuckDB",
      "Memo"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html",
    "href": "source/duckdb/cestquoi.html",
    "title": "DuckDB, c‚Äôest quoi ? ü¶Ü",
    "section": "",
    "text": "DuckDB se pr√©sente comme un SGBD (syst√®me de gestion de base de donn√©es) in-process, analytical, rapide, open-source, portable.\nVoyons ce que √ßa veut dire dans le d√©tail\n\n\nC‚Äôest l‚Äôun des points principaux de DuckDB : tout tourne au sein d‚Äôun m√™me processus.\nC‚Äôest donc diff√©rent des SGBD classiques qui ont des architectures client / serveur.\nDans un SGBD classique comme postgres, on peut distinguer 3 grands morceaux d‚Äôarchitecture :\n\nLe client : il envoie les requ√™tes au serveur et r√©cup√®re les r√©sultats\n\nLe serveur : tourne en permanence, re√ßoit les requ√™tes, les analyse, d√©termine et ex√©cute le plan d‚Äôex√©cution correspondant\n\nLe stockage physique des donn√©es : en g√©n√©ral le syst√®me de fichiers local au serveur postgres\n\nDans le cas de DuckDB, le client et le serveur sont confondus dans le m√™me processus et ce processus ne tourne que pour la dur√©e de la session DuckDB.\nLe stockage de donn√©es est d√©coupl√© de DuckDB. DuckDB travaille par d√©faut in-memory et s‚Äôappuie sur des sources de donn√©es externes (par exemple sur S3, wink-wink)\nEn r√©sum√© :\n\nArchitecture classique (type postgres) : client =&gt; serveur / stockage des donn√©es\n\nArchitecture Duckdb : client / serveur =&gt; sources multiples de donn√©es\n\n\n\n\nDuckDB est une base de donn√©es sp√©cialis√©e dans les traitements analytiques, par opposition aux bases de donn√©es habituelles sp√©cialis√©es dans le transactionnel.\nCette diff√©rence de paradigme se voit principalement √† 2 niveaux :\n\nAu lieu de travailler sur des donn√©es pr√©-structur√©es (coucou les formes normales), on va travailler directement sur les donn√©es brutes (.csv, .parquet)\nOn va se concentrer sur les lectures (analyse de la donn√©es) et pas sur les modifications unitaires (transactionnelles). Ca rejoint le pattern write once, read many vu pr√©c√©demment sur S3\n\n\n\n\nBon, tous les SGBD disent √ßa, vous v√©rifierez par vous-m√™me :)\n\n\n\nDuckDB se d√©cline dans √† peu pr√®s toutes les formes et langages possibles et est multi-plateforme. Dans la suite on va s‚Äôint√©resser √† sa version en ligne de commande mais il est aussi utilisable directement dans vos codes R, python, Java (sous forme de driver JDBC) et m√™me en version web via webassembly !\n\n\n\nDuckDB est capable de lire et de s‚Äôinterfacer avec de multiples sources de donn√©es (.csv, .parquet ‚Ä¶), diff√©rents protocoles (http brut, S3, base de donn√©es ‚Ä¶) et est presque enti√®rement compatible avec le dialecte PostgreSQL (cf Postgresql compatibility )",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#in-process",
    "href": "source/duckdb/cestquoi.html#in-process",
    "title": "DuckDB, c‚Äôest quoi ? ü¶Ü",
    "section": "",
    "text": "C‚Äôest l‚Äôun des points principaux de DuckDB : tout tourne au sein d‚Äôun m√™me processus.\nC‚Äôest donc diff√©rent des SGBD classiques qui ont des architectures client / serveur.\nDans un SGBD classique comme postgres, on peut distinguer 3 grands morceaux d‚Äôarchitecture :\n\nLe client : il envoie les requ√™tes au serveur et r√©cup√®re les r√©sultats\n\nLe serveur : tourne en permanence, re√ßoit les requ√™tes, les analyse, d√©termine et ex√©cute le plan d‚Äôex√©cution correspondant\n\nLe stockage physique des donn√©es : en g√©n√©ral le syst√®me de fichiers local au serveur postgres\n\nDans le cas de DuckDB, le client et le serveur sont confondus dans le m√™me processus et ce processus ne tourne que pour la dur√©e de la session DuckDB.\nLe stockage de donn√©es est d√©coupl√© de DuckDB. DuckDB travaille par d√©faut in-memory et s‚Äôappuie sur des sources de donn√©es externes (par exemple sur S3, wink-wink)\nEn r√©sum√© :\n\nArchitecture classique (type postgres) : client =&gt; serveur / stockage des donn√©es\n\nArchitecture Duckdb : client / serveur =&gt; sources multiples de donn√©es",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#analytical",
    "href": "source/duckdb/cestquoi.html#analytical",
    "title": "DuckDB, c‚Äôest quoi ? ü¶Ü",
    "section": "",
    "text": "DuckDB est une base de donn√©es sp√©cialis√©e dans les traitements analytiques, par opposition aux bases de donn√©es habituelles sp√©cialis√©es dans le transactionnel.\nCette diff√©rence de paradigme se voit principalement √† 2 niveaux :\n\nAu lieu de travailler sur des donn√©es pr√©-structur√©es (coucou les formes normales), on va travailler directement sur les donn√©es brutes (.csv, .parquet)\nOn va se concentrer sur les lectures (analyse de la donn√©es) et pas sur les modifications unitaires (transactionnelles). Ca rejoint le pattern write once, read many vu pr√©c√©demment sur S3",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#rapide",
    "href": "source/duckdb/cestquoi.html#rapide",
    "title": "DuckDB, c‚Äôest quoi ? ü¶Ü",
    "section": "",
    "text": "Bon, tous les SGBD disent √ßa, vous v√©rifierez par vous-m√™me :)",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#portable",
    "href": "source/duckdb/cestquoi.html#portable",
    "title": "DuckDB, c‚Äôest quoi ? ü¶Ü",
    "section": "",
    "text": "DuckDB se d√©cline dans √† peu pr√®s toutes les formes et langages possibles et est multi-plateforme. Dans la suite on va s‚Äôint√©resser √† sa version en ligne de commande mais il est aussi utilisable directement dans vos codes R, python, Java (sous forme de driver JDBC) et m√™me en version web via webassembly !",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#interop√©rable",
    "href": "source/duckdb/cestquoi.html#interop√©rable",
    "title": "DuckDB, c‚Äôest quoi ? ü¶Ü",
    "section": "",
    "text": "DuckDB est capable de lire et de s‚Äôinterfacer avec de multiples sources de donn√©es (.csv, .parquet ‚Ä¶), diff√©rents protocoles (http brut, S3, base de donn√©es ‚Ä¶) et est presque enti√®rement compatible avec le dialecte PostgreSQL (cf Postgresql compatibility )",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ecosyst√®me data : S3, duckDB, parquet",
    "section": "",
    "text": "Ce site propose un aper√ßu d‚Äôune partie de l‚Äô√©cosyst√®me moderne de traitement de donn√©es en abordant 3 technologies :\n\nS3 : le stockage objet\nDuckDB : un SGBD analytique\nParquet : un format de donn√©es orient√© colonnes\n\n\n\n\n\n\nLe code qui g√©n√®re les supports est disponible sur GitHub.\n\n\n\nPour approfondir sa connaissance apr√®s cette formation d‚Äôintroduction, rien de tel que la mise en pratique sur des sujets concrets !\n\n\n\n\n\npour toute demande : innovation@insee.fr"
  },
  {
    "objectID": "index.html#contexte",
    "href": "index.html#contexte",
    "title": "Ecosyst√®me data : S3, duckDB, parquet",
    "section": "",
    "text": "Ce site propose un aper√ßu d‚Äôune partie de l‚Äô√©cosyst√®me moderne de traitement de donn√©es en abordant 3 technologies :\n\nS3 : le stockage objet\nDuckDB : un SGBD analytique\nParquet : un format de donn√©es orient√© colonnes"
  },
  {
    "objectID": "index.html#et-apr√®s",
    "href": "index.html#et-apr√®s",
    "title": "Ecosyst√®me data : S3, duckDB, parquet",
    "section": "",
    "text": "Le code qui g√©n√®re les supports est disponible sur GitHub.\n\n\n\nPour approfondir sa connaissance apr√®s cette formation d‚Äôintroduction, rien de tel que la mise en pratique sur des sujets concrets !"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Ecosyst√®me data : S3, duckDB, parquet",
    "section": "",
    "text": "pour toute demande : innovation@insee.fr"
  },
  {
    "objectID": "slides/index.html#s3",
    "href": "slides/index.html#s3",
    "title": "D√©couverte S3",
    "section": "S3",
    "text": "S3"
  },
  {
    "objectID": "source/duckdb/letsgo.html",
    "href": "source/duckdb/letsgo.html",
    "title": "DuckDB, let‚Äôs go ! ü¶Ü",
    "section": "",
    "text": "Vous pouvez utiliser DuckDB de plein de mani√®res diff√©rentes. Ici on va tout faire en ligne de commande (CLI) mais vous √™tre encourag√©s √† tester les SDK de vos langages pr√©f√©r√©s !\nDuckDB CLI est distribu√© sous forme de binaire standalone, t√©l√©chargeable directement sur leur site documentaire.\nIl est par ailleurs pr√©install√© dans la majorit√© des environnements modernes de datascience dont les environnements lanc√©s par Onyxia\n\n\n\nLancer duckdb :\ngon@laboitemagique:~$ duckdb\nv1.3.0 (Ossivalis) 71c5c07cdd\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nOn constate bien que duckdb travaille uniquement en m√©moire (transient in-memory database). Toutes les donn√©es seront donc perdues √† la fin de la session.\nSi on veut qu‚Äôil sauvegarde ses tables, on peut pr√©ciser un fichier de database au moment du lancement duckdb madb.db ou √† chaud pendant une session : .open madb.db.\n\n\n\nhttps://duckdb.org/docs/stable/sql/introduction.html\n\n\n\nPour configurer la CLI vous avez la possibilit√© de cr√©er un fichier .duckdbrc √† la racine de votre r√©pertoire personnel ($HOME). Ce fichier vous permettra d‚Äôex√©cuter du code au lancement de votre session duckdb.\n.prompt 'duckdb&gt;'\nCREATE OR REPLACE SECRET secret ( TYPE s3, PROVIDER credential_chain, CHAIN \"env;config\", PROFILE 'default',  ENDPOINT \"minio.lab.sspcloud.fr\" );",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#installation",
    "href": "source/duckdb/letsgo.html#installation",
    "title": "DuckDB, let‚Äôs go ! ü¶Ü",
    "section": "",
    "text": "Vous pouvez utiliser DuckDB de plein de mani√®res diff√©rentes. Ici on va tout faire en ligne de commande (CLI) mais vous √™tre encourag√©s √† tester les SDK de vos langages pr√©f√©r√©s !\nDuckDB CLI est distribu√© sous forme de binaire standalone, t√©l√©chargeable directement sur leur site documentaire.\nIl est par ailleurs pr√©install√© dans la majorit√© des environnements modernes de datascience dont les environnements lanc√©s par Onyxia",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#premi√®re-utilisation",
    "href": "source/duckdb/letsgo.html#premi√®re-utilisation",
    "title": "DuckDB, let‚Äôs go ! ü¶Ü",
    "section": "",
    "text": "Lancer duckdb :\ngon@laboitemagique:~$ duckdb\nv1.3.0 (Ossivalis) 71c5c07cdd\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nOn constate bien que duckdb travaille uniquement en m√©moire (transient in-memory database). Toutes les donn√©es seront donc perdues √† la fin de la session.\nSi on veut qu‚Äôil sauvegarde ses tables, on peut pr√©ciser un fichier de database au moment du lancement duckdb madb.db ou √† chaud pendant une session : .open madb.db.",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#hello-world",
    "href": "source/duckdb/letsgo.html#hello-world",
    "title": "DuckDB, let‚Äôs go ! ü¶Ü",
    "section": "",
    "text": "https://duckdb.org/docs/stable/sql/introduction.html",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#optionnel-configuration",
    "href": "source/duckdb/letsgo.html#optionnel-configuration",
    "title": "DuckDB, let‚Äôs go ! ü¶Ü",
    "section": "",
    "text": "Pour configurer la CLI vous avez la possibilit√© de cr√©er un fichier .duckdbrc √† la racine de votre r√©pertoire personnel ($HOME). Ce fichier vous permettra d‚Äôex√©cuter du code au lancement de votre session duckdb.\n.prompt 'duckdb&gt;'\nCREATE OR REPLACE SECRET secret ( TYPE s3, PROVIDER credential_chain, CHAIN \"env;config\", PROFILE 'default',  ENDPOINT \"minio.lab.sspcloud.fr\" );",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/parquet/cestquoi.html",
    "href": "source/parquet/cestquoi.html",
    "title": "Parquet, c‚Äôest quoi ?",
    "section": "",
    "text": "Parquet est un format de fichier orient√© colonne d√©velopp√© en 2013 par Cloudera et Twitter en 2013, avant d‚Äô√™tre offert √† la fondation Apache en 2014 en tant que projet open-source.\nPour bien d√©finir ce qu‚Äôest un format de fichier orient√© colonne, rappelons d‚Äôabord ce qu‚Äôest un format de fichier orient√© ligne. Dans les formats de fichiers orient√©s ligne, les donn√©es sont enregistr√©es ligne par ligne ce qui rend le format de fichier optimis√© pour les syst√®mes transactionnels quand il y a besoin de lire ou enregistrer l‚Äôint√©grit√© d‚Äôun enregistrement.\nPour les formats de fichiers orient√©s colonne, la donn√©e est enregistr√©e par colonne. cela rend le format de fichier tr√®s int√©ressant pour les analyses. Ainsi, pour filtrer l‚Äôinformation sur une colonne pr√©cise, il n‚Äôy a pas besoin de charger toute une ligne mais seulement la colonne qui nous int√©resse selon la requ√™te effectu√©e, ce qui nous permet d‚Äôam√©liorer les performances. De plus, le format de fichiers orient√© colonne permet le vectorized processing: les op√©rations sont effectu√©es par lots de valeurs de colonne au lieu de ligne √† ligne. Les moteurs d‚Äôex√©cution (DuckDB, Trino, Spark) peuvent ainsi ex√©cuter le m√™me calcul sur des dizaines de valeurs au cours d‚Äôun cycle plut√¥t qu‚Äôune ligne √† la fois. Enfin, les formats de fichiers orient√©s colonne sont des formats compress√©s ce qui permet un gain d‚Äôespace.\n\n\nQuelques √©l√©ments composant un fichier parquet :\n- row group : partition horizontale des donn√©es, chaque groupe contient toutes les colonnes d‚Äôun sous-ensemble de lignes. Il s‚Äôagit de la plus grande unit√© de travail.\n- column chunk : colonne au sein d‚Äôun row group ce qui permet de r√©aliser une compression et encodage par colonne.\n- page : plus petite unit√© de donn√©es au sein d‚Äôun column chunk.On y retrouve :\n- Data Pages : valeur actuelle\n- Footer : metadatas comme le schema, les row groups, des statistiques‚Ä¶",
    "crumbs": [
      "Parquet",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/parquet/cestquoi.html#composition-dun-fichier-parquet",
    "href": "source/parquet/cestquoi.html#composition-dun-fichier-parquet",
    "title": "Parquet, c‚Äôest quoi ?",
    "section": "",
    "text": "Quelques √©l√©ments composant un fichier parquet :\n- row group : partition horizontale des donn√©es, chaque groupe contient toutes les colonnes d‚Äôun sous-ensemble de lignes. Il s‚Äôagit de la plus grande unit√© de travail.\n- column chunk : colonne au sein d‚Äôun row group ce qui permet de r√©aliser une compression et encodage par colonne.\n- page : plus petite unit√© de donn√©es au sein d‚Äôun column chunk.On y retrouve :\n- Data Pages : valeur actuelle\n- Footer : metadatas comme le schema, les row groups, des statistiques‚Ä¶",
    "crumbs": [
      "Parquet",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/parquet/memo.html",
    "href": "source/parquet/memo.html",
    "title": "Memo Parquet",
    "section": "",
    "text": "import pandas as pd\nimport s3fs\n\ns3 = s3fs.S3FileSystem()\ndf = pd.read_parquet('my-bucket/my-file.parquet', filesystem=s3, engine='pyarrow')\n\n\n\n\nimport s3fs\nimport pyarrow.parquet as pq\n\ns3 = s3fs.S3FileSystem()\ndf = pq.read_table('my-bucket/my-file.parquet', filesystem=s3)",
    "crumbs": [
      "Parquet",
      "Memo"
    ]
  },
  {
    "objectID": "source/parquet/memo.html#en-utilisant-pandas",
    "href": "source/parquet/memo.html#en-utilisant-pandas",
    "title": "Memo Parquet",
    "section": "",
    "text": "import pandas as pd\nimport s3fs\n\ns3 = s3fs.S3FileSystem()\ndf = pd.read_parquet('my-bucket/my-file.parquet', filesystem=s3, engine='pyarrow')",
    "crumbs": [
      "Parquet",
      "Memo"
    ]
  },
  {
    "objectID": "source/parquet/memo.html#en-utilisant-pyarrow",
    "href": "source/parquet/memo.html#en-utilisant-pyarrow",
    "title": "Memo Parquet",
    "section": "",
    "text": "import s3fs\nimport pyarrow.parquet as pq\n\ns3 = s3fs.S3FileSystem()\ndf = pq.read_table('my-bucket/my-file.parquet', filesystem=s3)",
    "crumbs": [
      "Parquet",
      "Memo"
    ]
  },
  {
    "objectID": "source/s3/letsgo.html",
    "href": "source/s3/letsgo.html",
    "title": "S3, let‚Äôs go !",
    "section": "",
    "text": "Il est temps de pratiquer :)\n\n\nVous √™tes libres de choisir le serveur S3 auquel vous allez vous connecter.\nVous pouvez m√™me d√©ployer votre propre serveur S3 par exemple en installant minIO\nDans la suite, par simplicit√© de configuration, on utilisera un service d√©ploy√© par Onyxia (par exemple sur le SSPCloud).\nLa configuration S3 est alors automatiquement inject√©e via les variables d‚Äôenvironnement. Le confirmer via env : AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_DEFAULT_REGION, AWS_S3_ENDPOINT.\nSur ces environnements, vous avez les droits sur le bucket du nom de votre identifiant (ou, sur certaines plateformes, √† un sous-path d‚Äôun bucket) Confirmer qu‚Äôon peut bien acc√©der avec mc ls s3/votreidentifiant\nVous avez aussi, via Onyxia, acc√®s √† une interface graphique cliente S3 (onglet mes fichiers)",
    "crumbs": [
      "S3",
      "Let's go !"
    ]
  },
  {
    "objectID": "source/s3/letsgo.html#mise-en-place",
    "href": "source/s3/letsgo.html#mise-en-place",
    "title": "S3, let‚Äôs go !",
    "section": "",
    "text": "Vous √™tes libres de choisir le serveur S3 auquel vous allez vous connecter.\nVous pouvez m√™me d√©ployer votre propre serveur S3 par exemple en installant minIO\nDans la suite, par simplicit√© de configuration, on utilisera un service d√©ploy√© par Onyxia (par exemple sur le SSPCloud).\nLa configuration S3 est alors automatiquement inject√©e via les variables d‚Äôenvironnement. Le confirmer via env : AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_DEFAULT_REGION, AWS_S3_ENDPOINT.\nSur ces environnements, vous avez les droits sur le bucket du nom de votre identifiant (ou, sur certaines plateformes, √† un sous-path d‚Äôun bucket) Confirmer qu‚Äôon peut bien acc√©der avec mc ls s3/votreidentifiant\nVous avez aussi, via Onyxia, acc√®s √† une interface graphique cliente S3 (onglet mes fichiers)",
    "crumbs": [
      "S3",
      "Let's go !"
    ]
  }
]