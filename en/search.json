[
  {
    "objectID": "source/s3/memo.html",
    "href": "source/s3/memo.html",
    "title": "Se connecter à S3",
    "section": "",
    "text": "Pour configurer sa connection à s3, des variables d’environnement et fichiers de configuration sont reconnus par la plupart des librairies. Ainsi, si seul un endpoint est utilisé, on pourra souvent se contenter d’utiliser des variables d’environnement (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_DEFAULT_REGION, ENDPOINT_URL). Au delà d’un endpoint, et afin de gagner en flexibilité, il est possible de créer des fichiers de configuration situés à la racine du répertoire utilisateur ($HOME). Les fichiers sont découpés en profiles permettant de configurer différents paramètres et credentials. Le fichier .aws/config permet de définir les endpoints d’intérêt, tandis que le fichier .aws/credentials sert à stocker les credentials associés. Par défaut, s’il existe, le profil default sera utilisé.\n.aws/config\n[default]\nregion = us-east-1\nendpoint_url = https://my-minio\n\n[profile test]\nregion = us-east-1\nendpoint_url = https://my-minio2\n\n.aws/credentials\n[default]\naws_access_key_id = default_access_key\naws_secret_access_key = default_secret_access_key\naws_session_token = default_token\n\n[test]\naws_access_key_id = test_access_key\naws_secret_access_key = test_secret_acess_key\n\n\nimport s3fs\n\nfs = s3fs.S3FileSystem(\n    client_kwargs={'endpoint_url': ENDPOINT_URL},\n    key = AWS_ACCESS_KEY_ID, \n    secret = AWS_SECRET_ACCESS_KEY, \n    token = AWS_SESSION_TOKEN\"),\n\nAvec des fichiers de config\nimport s3fs\n\nfs = s3fs.S3FileSystem()\nfiles = fs.ls('inesh')\nprint(files)\nSi on veut changer de profil\nimport s3fs\n\nfs = s3fs.S3FileSystem(profile=\"toto\")\nfiles = fs.ls('inesh')\nprint(files)\n\n\n\nimport boto3\n\nclient = boto3.client(\n    's3',\n    aws_access_key_id=ACCESS_KEY,\n    aws_secret_access_key=SECRET_KEY,\n    aws_session_token=SESSION_TOKEN,\n    endpoint_url=ENDPOINT_URL,\n)\nAvec des fichiers de config,\nimport boto3\nclient = boto3.client('s3)\n\nresponse = client.list_objects_v2(Bucket='inesh')\nprint(response)\n\nSi on veut changer de profil\nimport boto3\n\nsession = boto3.Session(profile_name='toto')\ns3_client = session.client(service_name='s3')\n\n\n\n\nPour configurer mc : une variable d’environnement suffit : MC_HOST_ALIAS = “https://::@” exemple:\nexport MC_HOST_s3 = \"https://$AWS_ACCESS_KEY_ID$:AWS_SECRET_ACCESS_KEY:AWS_SESSION_TOKEN@$ENDPOINT_URL$\"\nUne fois le tout configuré, nous pouvons lister le contenu de notre bucket\nmc ls s3/my-bucket\ncopier un fichier\nmc cp s3/my-bucket/my-file.txt s3/my-bucket/somewhere-else/my-file.txt\nle télécharger\nmc get s3/my-bucket/my-file.txt ./data/my-file.txt\nle supprimer\nmc rm s3/my-bucket/my-file.txt\nl’uploader\nmc cp ./data/my-file.txt s3/my-bucket/my-second-file.txt",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/memo.html#en-utilisant-s3fs",
    "href": "source/s3/memo.html#en-utilisant-s3fs",
    "title": "Se connecter à S3",
    "section": "",
    "text": "import s3fs\n\nfs = s3fs.S3FileSystem(\n    client_kwargs={'endpoint_url': ENDPOINT_URL},\n    key = AWS_ACCESS_KEY_ID, \n    secret = AWS_SECRET_ACCESS_KEY, \n    token = AWS_SESSION_TOKEN\"),\n\nAvec des fichiers de config\nimport s3fs\n\nfs = s3fs.S3FileSystem()\nfiles = fs.ls('inesh')\nprint(files)\nSi on veut changer de profil\nimport s3fs\n\nfs = s3fs.S3FileSystem(profile=\"toto\")\nfiles = fs.ls('inesh')\nprint(files)",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/memo.html#en-utilisant-boto3",
    "href": "source/s3/memo.html#en-utilisant-boto3",
    "title": "Se connecter à S3",
    "section": "",
    "text": "import boto3\n\nclient = boto3.client(\n    's3',\n    aws_access_key_id=ACCESS_KEY,\n    aws_secret_access_key=SECRET_KEY,\n    aws_session_token=SESSION_TOKEN,\n    endpoint_url=ENDPOINT_URL,\n)\nAvec des fichiers de config,\nimport boto3\nclient = boto3.client('s3)\n\nresponse = client.list_objects_v2(Bucket='inesh')\nprint(response)\n\nSi on veut changer de profil\nimport boto3\n\nsession = boto3.Session(profile_name='toto')\ns3_client = session.client(service_name='s3')",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/memo.html#en-utilisant-mc-cli",
    "href": "source/s3/memo.html#en-utilisant-mc-cli",
    "title": "Se connecter à S3",
    "section": "",
    "text": "Pour configurer mc : une variable d’environnement suffit : MC_HOST_ALIAS = “https://::@” exemple:\nexport MC_HOST_s3 = \"https://$AWS_ACCESS_KEY_ID$:AWS_SECRET_ACCESS_KEY:AWS_SESSION_TOKEN@$ENDPOINT_URL$\"\nUne fois le tout configuré, nous pouvons lister le contenu de notre bucket\nmc ls s3/my-bucket\ncopier un fichier\nmc cp s3/my-bucket/my-file.txt s3/my-bucket/somewhere-else/my-file.txt\nle télécharger\nmc get s3/my-bucket/my-file.txt ./data/my-file.txt\nle supprimer\nmc rm s3/my-bucket/my-file.txt\nl’uploader\nmc cp ./data/my-file.txt s3/my-bucket/my-second-file.txt",
    "crumbs": [
      "S3",
      "Memo utile"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html",
    "href": "source/s3/cestquoi.html",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "S3 est un protocole de stockage objet dérivé du service initialement offert par le cloud provider AWS.\n\n\nPour comprendre l’intérêt du stockage objet il faut d’abord identifier les limites des solutions de stockage historiques.\nHistoriquement, les offres principales de stockage disponibles dans les infrastructures informatiques sont des offres dites block storage ou file storage. Même s’il existe des différences et tout un tas d’implémentations différentes de ces deux systèmes, le résultat pour un développeur ou un statisticien est souvent le même : un partage réseau monté directement sur ses environnements d’exécution (poste de travail, serveur distant …).\nLes limites de ces systèmes sont multiples :\n\nIls constituent un frein majeur à la portabilité : un process ne pourra s’exécuter que sur un environnement où les données sont montées\n\nIls constituent un frein majeur à l’intéropérabilité : ces systèmes sont souvent très adhérents à l’infrastructure de données\nIls constituent un frein majeur à la scalabilité : ces systèmes ne sont pas pensés pour être montés et utilisés par des centaines de process simultanément\n\nIls induisent une charge sur les équipes d’infra qui doivent préconfigurer tous les environnements pour y monter les “bons” partages\n\nLe modèle de sécurité associé est imparfait : pour ces systèmes, le contrôle d’accès se fait souvent au moment du montage de la ressource. Une fois la ressource accessible à l’environnement, les accès unitaires sont plus difficilement traçables, auditables et validables\n\n\n\n\nLe stockage objet apporte des solutions aux problématiques précédentes en inversant l’approche.\nAu lieu de rendre disponible les données en les montant directement dans les environnements, c’est l’applicatif qui va directement requêter les données au moment de leur utilisation.\n\nLes environnements d’exécution n’ont plus de prérequis ce qui offre une flexibilité, portabilité et intéropérabilité incroyable\nLe modèle de sécurité passe à un contrôle d’accès par requête, beaucoup plus fin, traçable et auditable\nLe système est nativement scalable\n\n\n\n\nS3 est un protocole implémentant les principes du stockage objet.\nIl est important de faire la distinction entre S3 (le protocole) et AWS S3 (le service S3 hébergé chez AWS).\nIl est donc tout à fait possible d’installer un serveur compatible S3 chez soi. Citons 2 implémentations : minIO & CEPH.\n\n\n\nS3 expose une API REST HTTP. Toute intéraction avec un serveur S3 passe par des requêtes HTTP que ça soit pour télécharger, uploader ou supprimer des données ou même pour le configurer.\nComme pour toute API, la première étape pour discuter avec est d’obtenir son URL.\nPar exemple:\n\nAWS S3 : http://s3.amazonaws.com/ - qui est très souvent configuré par défaut, autant pour les librairies que pour les clients.\nSSP CLOUD : https://minio.lab.sspcloud.fr\nLS3 : https://minio.datascience.kube.insee.fr\npour un usage interne : https://minio.dev.kube.insee.fr …\n\n\n\n\nSans le savoir vous faites déjà des tonnes de requêtes vers des serveurs S3 tout les jours.\nPar exemple, ce chat vous est offert par un serveur S3 : \nCette image est disponible directement à l’URL https://minio.lab.sspcloud.fr/f2wbnp/public/chat.jpg\nPour les fichiers publics, le téléchargement se fait simplement via une requête GET classique.\nL’objet possède une URL composée de :\n\nURL de base du serveur S3 : https://minio.lab.sspcloud.fr\n\nNom du bucket : f2wbnp (à noter que pour la plupart des serveurs S3, l’accès est aussi possible via un sous-domaine correspondant au bucket : https://f2wbnp.minio.lab.sspcloud.fr/public/chat.jpg , on parle alors de virtual host style access plutôt que path style access)\n\nChemin de l’objet au sein du bucket : public/chat.jpg\n\nUn bucket correspond en gros à un dossier à la racine du serveur S3. Les buckets permettent de séparer les usages, les permissions, les quotas …\nEn fonction du serveur S3 que vous utilisez et des permissions que vous avez, vous pouvez avoir accès à tout ou partie d’un ou plusieurs buckets.\n\n\nA part pour l’accès aux données explicitement rendues publiques (la gestion de la visibilité et des permissions sur les fichiers se fait en général via un système de policies qui n’est pas abordé dans cette présentation), il faudra des informations d’authentification (credentials) pour communiquer avec l’API.\nCes credentials sont constitués d’un duo access key & secret key (en gros login / mot de passe) pour les comptes de service et d’un trio access key, secret key, session token pour les identités temporaires (credentials personnels, expirant au bout d’un certain temps).\nPourront être utilisées les variables d’environnements suivantes, généralement reconnues par les bibliothèques standards S3 :\nAWS_ACCESS_KEY_ID=my_access_key AWS_SECRET_ACCESS_KEY=my_secret_key AWS_SESSION_TOKEN = my_session_token ENDPOINT_URL = s3_endpoint\nPour récupérer vos credentials, vous pouvez vous rendre sur - LS3 / SSPCLOUD : onglet my account &gt; Connect to storage et sélectionner shell environment variable\n\n\n\n\nAfin de simplifier les intéractions avec l’API S3, nous allons utiliser un client s3. Cela permettra de gérer l’authentification et de construire les requêtes HTTP correspondant à vos commandes.\nDes exemples de clients s3 en ligne de commande :\n\nmc (minIO Client) : compatible pour tout service compatible s3\ns3cmd : compatible pour tout service compatible s3\n\naws cli : outil officiel pour intéragir avec Amazon S3\nrclone : couteau suisse multicloud, supporte d’autres protocoles que S3\n\nIl existe évidemment des interfaces graphiques ainsi que des bibliothèques (SDK) pour tous les langages.\nVous êtes évidemment libres d’utiliser le client S3 de votre choix, en fonction de vos préférences.\nDans la suite on illustrera à partir du client mc mais vous êtes encouragés à tester différents clients.\nDans tous les cas, client + URL + credentials = ça marche :)\n\n\n\nS3 (et plus généralement le stockage objet) est parfait pour un certain nombre d’usages mais pas tous.\nLes principales limitations sont les suivantes :\n\nL’écriture partielle n’est pas possible : un fichier ne peut pas être modifié. La moindre modification (y compris renommage) correspond à la réécriture complète du fichier\n\nLa latence est plus forte que pour un stockage block / fichiers classique : il n’est donc pas adapté pour des systèmes ayant besoin d’une latence faible comme les bases de données relationnelles\n\nDu coup on en tire quelques leçons :\n\nWrite once, read many : S3 est particulièrement adapté à ce pattern. Parfait pour les backups, les logs, les ressources statiques, la diffusion des repertoires\nS3 n’a pas vocation à remplacer entièrement les stockages block / fichiers existants mais à venir en complément pour les bons cas d’usage\n\n\n\n\nhttps://docs.sspcloud.fr/content/storage.html",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#les-limites-des-offres-de-stockage-historiques",
    "href": "source/s3/cestquoi.html#les-limites-des-offres-de-stockage-historiques",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "Pour comprendre l’intérêt du stockage objet il faut d’abord identifier les limites des solutions de stockage historiques.\nHistoriquement, les offres principales de stockage disponibles dans les infrastructures informatiques sont des offres dites block storage ou file storage. Même s’il existe des différences et tout un tas d’implémentations différentes de ces deux systèmes, le résultat pour un développeur ou un statisticien est souvent le même : un partage réseau monté directement sur ses environnements d’exécution (poste de travail, serveur distant …).\nLes limites de ces systèmes sont multiples :\n\nIls constituent un frein majeur à la portabilité : un process ne pourra s’exécuter que sur un environnement où les données sont montées\n\nIls constituent un frein majeur à l’intéropérabilité : ces systèmes sont souvent très adhérents à l’infrastructure de données\nIls constituent un frein majeur à la scalabilité : ces systèmes ne sont pas pensés pour être montés et utilisés par des centaines de process simultanément\n\nIls induisent une charge sur les équipes d’infra qui doivent préconfigurer tous les environnements pour y monter les “bons” partages\n\nLe modèle de sécurité associé est imparfait : pour ces systèmes, le contrôle d’accès se fait souvent au moment du montage de la ressource. Une fois la ressource accessible à l’environnement, les accès unitaires sont plus difficilement traçables, auditables et validables",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#le-stockage-objet",
    "href": "source/s3/cestquoi.html#le-stockage-objet",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "Le stockage objet apporte des solutions aux problématiques précédentes en inversant l’approche.\nAu lieu de rendre disponible les données en les montant directement dans les environnements, c’est l’applicatif qui va directement requêter les données au moment de leur utilisation.\n\nLes environnements d’exécution n’ont plus de prérequis ce qui offre une flexibilité, portabilité et intéropérabilité incroyable\nLe modèle de sécurité passe à un contrôle d’accès par requête, beaucoup plus fin, traçable et auditable\nLe système est nativement scalable",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#s3",
    "href": "source/s3/cestquoi.html#s3",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "S3 est un protocole implémentant les principes du stockage objet.\nIl est important de faire la distinction entre S3 (le protocole) et AWS S3 (le service S3 hébergé chez AWS).\nIl est donc tout à fait possible d’installer un serveur compatible S3 chez soi. Citons 2 implémentations : minIO & CEPH.",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#s3-une-api-http",
    "href": "source/s3/cestquoi.html#s3-une-api-http",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "S3 expose une API REST HTTP. Toute intéraction avec un serveur S3 passe par des requêtes HTTP que ça soit pour télécharger, uploader ou supprimer des données ou même pour le configurer.\nComme pour toute API, la première étape pour discuter avec est d’obtenir son URL.\nPar exemple:\n\nAWS S3 : http://s3.amazonaws.com/ - qui est très souvent configuré par défaut, autant pour les librairies que pour les clients.\nSSP CLOUD : https://minio.lab.sspcloud.fr\nLS3 : https://minio.datascience.kube.insee.fr\npour un usage interne : https://minio.dev.kube.insee.fr …",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#premier-contact",
    "href": "source/s3/cestquoi.html#premier-contact",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "Sans le savoir vous faites déjà des tonnes de requêtes vers des serveurs S3 tout les jours.\nPar exemple, ce chat vous est offert par un serveur S3 : \nCette image est disponible directement à l’URL https://minio.lab.sspcloud.fr/f2wbnp/public/chat.jpg\nPour les fichiers publics, le téléchargement se fait simplement via une requête GET classique.\nL’objet possède une URL composée de :\n\nURL de base du serveur S3 : https://minio.lab.sspcloud.fr\n\nNom du bucket : f2wbnp (à noter que pour la plupart des serveurs S3, l’accès est aussi possible via un sous-domaine correspondant au bucket : https://f2wbnp.minio.lab.sspcloud.fr/public/chat.jpg , on parle alors de virtual host style access plutôt que path style access)\n\nChemin de l’objet au sein du bucket : public/chat.jpg\n\nUn bucket correspond en gros à un dossier à la racine du serveur S3. Les buckets permettent de séparer les usages, les permissions, les quotas …\nEn fonction du serveur S3 que vous utilisez et des permissions que vous avez, vous pouvez avoir accès à tout ou partie d’un ou plusieurs buckets.\n\n\nA part pour l’accès aux données explicitement rendues publiques (la gestion de la visibilité et des permissions sur les fichiers se fait en général via un système de policies qui n’est pas abordé dans cette présentation), il faudra des informations d’authentification (credentials) pour communiquer avec l’API.\nCes credentials sont constitués d’un duo access key & secret key (en gros login / mot de passe) pour les comptes de service et d’un trio access key, secret key, session token pour les identités temporaires (credentials personnels, expirant au bout d’un certain temps).\nPourront être utilisées les variables d’environnements suivantes, généralement reconnues par les bibliothèques standards S3 :\nAWS_ACCESS_KEY_ID=my_access_key AWS_SECRET_ACCESS_KEY=my_secret_key AWS_SESSION_TOKEN = my_session_token ENDPOINT_URL = s3_endpoint\nPour récupérer vos credentials, vous pouvez vous rendre sur - LS3 / SSPCLOUD : onglet my account &gt; Connect to storage et sélectionner shell environment variable",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#un-client-pour-communiquer-avec-s3",
    "href": "source/s3/cestquoi.html#un-client-pour-communiquer-avec-s3",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "Afin de simplifier les intéractions avec l’API S3, nous allons utiliser un client s3. Cela permettra de gérer l’authentification et de construire les requêtes HTTP correspondant à vos commandes.\nDes exemples de clients s3 en ligne de commande :\n\nmc (minIO Client) : compatible pour tout service compatible s3\ns3cmd : compatible pour tout service compatible s3\n\naws cli : outil officiel pour intéragir avec Amazon S3\nrclone : couteau suisse multicloud, supporte d’autres protocoles que S3\n\nIl existe évidemment des interfaces graphiques ainsi que des bibliothèques (SDK) pour tous les langages.\nVous êtes évidemment libres d’utiliser le client S3 de votre choix, en fonction de vos préférences.\nDans la suite on illustrera à partir du client mc mais vous êtes encouragés à tester différents clients.\nDans tous les cas, client + URL + credentials = ça marche :)",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#cas-dusages-et-limites",
    "href": "source/s3/cestquoi.html#cas-dusages-et-limites",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "S3 (et plus généralement le stockage objet) est parfait pour un certain nombre d’usages mais pas tous.\nLes principales limitations sont les suivantes :\n\nL’écriture partielle n’est pas possible : un fichier ne peut pas être modifié. La moindre modification (y compris renommage) correspond à la réécriture complète du fichier\n\nLa latence est plus forte que pour un stockage block / fichiers classique : il n’est donc pas adapté pour des systèmes ayant besoin d’une latence faible comme les bases de données relationnelles\n\nDu coup on en tire quelques leçons :\n\nWrite once, read many : S3 est particulièrement adapté à ce pattern. Parfait pour les backups, les logs, les ressources statiques, la diffusion des repertoires\nS3 n’a pas vocation à remplacer entièrement les stockages block / fichiers existants mais à venir en complément pour les bons cas d’usage",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/s3/cestquoi.html#aller-plus-loin",
    "href": "source/s3/cestquoi.html#aller-plus-loin",
    "title": "S3, c’est quoi ?",
    "section": "",
    "text": "https://docs.sspcloud.fr/content/storage.html",
    "crumbs": [
      "S3",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/parquet/letsgo.html",
    "href": "source/parquet/letsgo.html",
    "title": "Parquet, let’s go !",
    "section": "",
    "text": "Parquet, let’s go !\nPour pratiquer du parquet on va utiliser DuckDB mais il est tout à fait possible d’exploiter les fichiers parquet directement en utilisant les bibliothèques adaptées à votre langage (cf le mémo).\nDonnées du RP sur data.gouv.fr : https://www.data.gouv.fr/fr/datasets/recensement-de-la-population-fichiers-detail-individus-localises-au-canton-ou-ville/",
    "crumbs": [
      "Parquet",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/memo.html",
    "href": "source/duckdb/memo.html",
    "title": "Memo DuckDB 🦆",
    "section": "",
    "text": "Memo DuckDB 🦆",
    "crumbs": [
      "DuckDB",
      "Memo"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html",
    "href": "source/duckdb/cestquoi.html",
    "title": "DuckDB, c’est quoi ? 🦆",
    "section": "",
    "text": "DuckDB se présente comme un SGBD (système de gestion de base de données) in-process, analytical, rapide, open-source, portable.\nVoyons ce que ça veut dire dans le détail\n\n\nC’est l’un des points principaux de DuckDB : tout tourne au sein d’un même processus.\nC’est donc différent des SGBD classiques qui ont des architectures client / serveur.\nDans un SGBD classique comme postgres, on peut distinguer 3 grands morceaux d’architecture :\n\nLe client : il envoie les requêtes au serveur et récupère les résultats\n\nLe serveur : tourne en permanence, reçoit les requêtes, les analyse, détermine et exécute le plan d’exécution correspondant\n\nLe stockage physique des données : en général le système de fichiers local au serveur postgres\n\nDans le cas de DuckDB, le client et le serveur sont confondus dans le même processus et ce processus ne tourne que pour la durée de la session DuckDB.\nLe stockage de données est découplé de DuckDB. DuckDB travaille par défaut in-memory et s’appuie sur des sources de données externes (par exemple sur S3, wink-wink)\nEn résumé :\n\nArchitecture classique (type postgres) : client =&gt; serveur / stockage des données\n\nArchitecture Duckdb : client / serveur =&gt; sources multiples de données\n\n\n\n\nDuckDB est une base de données spécialisée dans les traitements analytiques, par opposition aux bases de données habituelles spécialisées dans le transactionnel.\nCette différence de paradigme se voit principalement à 2 niveaux :\n\nAu lieu de travailler sur des données pré-structurées (coucou les formes normales), on va travailler directement sur les données brutes (.csv, .parquet)\nOn va se concentrer sur les lectures (analyse de la données) et pas sur les modifications unitaires (transactionnelles). Ca rejoint le pattern write once, read many vu précédemment sur S3\n\n\n\n\nBon, tous les SGBD disent ça, vous vérifierez par vous-même :)\n\n\n\nDuckDB se décline dans à peu près toutes les formes et langages possibles et est multi-plateforme. Dans la suite on va s’intéresser à sa version en ligne de commande mais il est aussi utilisable directement dans vos codes R, python, Java (sous forme de driver JDBC) et même en version web via webassembly !\n\n\n\nDuckDB est capable de lire et de s’interfacer avec de multiples sources de données (.csv, .parquet …), différents protocoles (http brut, S3, base de données …) et est presque entièrement compatible avec le dialecte PostgreSQL (cf Postgresql compatibility )",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#in-process",
    "href": "source/duckdb/cestquoi.html#in-process",
    "title": "DuckDB, c’est quoi ? 🦆",
    "section": "",
    "text": "C’est l’un des points principaux de DuckDB : tout tourne au sein d’un même processus.\nC’est donc différent des SGBD classiques qui ont des architectures client / serveur.\nDans un SGBD classique comme postgres, on peut distinguer 3 grands morceaux d’architecture :\n\nLe client : il envoie les requêtes au serveur et récupère les résultats\n\nLe serveur : tourne en permanence, reçoit les requêtes, les analyse, détermine et exécute le plan d’exécution correspondant\n\nLe stockage physique des données : en général le système de fichiers local au serveur postgres\n\nDans le cas de DuckDB, le client et le serveur sont confondus dans le même processus et ce processus ne tourne que pour la durée de la session DuckDB.\nLe stockage de données est découplé de DuckDB. DuckDB travaille par défaut in-memory et s’appuie sur des sources de données externes (par exemple sur S3, wink-wink)\nEn résumé :\n\nArchitecture classique (type postgres) : client =&gt; serveur / stockage des données\n\nArchitecture Duckdb : client / serveur =&gt; sources multiples de données",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#analytical",
    "href": "source/duckdb/cestquoi.html#analytical",
    "title": "DuckDB, c’est quoi ? 🦆",
    "section": "",
    "text": "DuckDB est une base de données spécialisée dans les traitements analytiques, par opposition aux bases de données habituelles spécialisées dans le transactionnel.\nCette différence de paradigme se voit principalement à 2 niveaux :\n\nAu lieu de travailler sur des données pré-structurées (coucou les formes normales), on va travailler directement sur les données brutes (.csv, .parquet)\nOn va se concentrer sur les lectures (analyse de la données) et pas sur les modifications unitaires (transactionnelles). Ca rejoint le pattern write once, read many vu précédemment sur S3",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#rapide",
    "href": "source/duckdb/cestquoi.html#rapide",
    "title": "DuckDB, c’est quoi ? 🦆",
    "section": "",
    "text": "Bon, tous les SGBD disent ça, vous vérifierez par vous-même :)",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#portable",
    "href": "source/duckdb/cestquoi.html#portable",
    "title": "DuckDB, c’est quoi ? 🦆",
    "section": "",
    "text": "DuckDB se décline dans à peu près toutes les formes et langages possibles et est multi-plateforme. Dans la suite on va s’intéresser à sa version en ligne de commande mais il est aussi utilisable directement dans vos codes R, python, Java (sous forme de driver JDBC) et même en version web via webassembly !",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/duckdb/cestquoi.html#interopérable",
    "href": "source/duckdb/cestquoi.html#interopérable",
    "title": "DuckDB, c’est quoi ? 🦆",
    "section": "",
    "text": "DuckDB est capable de lire et de s’interfacer avec de multiples sources de données (.csv, .parquet …), différents protocoles (http brut, S3, base de données …) et est presque entièrement compatible avec le dialecte PostgreSQL (cf Postgresql compatibility )",
    "crumbs": [
      "DuckDB",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ecosystème data : S3, duckDB, parquet",
    "section": "",
    "text": "Ce site propose un aperçu d’une partie de l’écosystème moderne de traitement de données en abordant 3 technologies :\n\nS3 : le stockage objet\nDuckDB : un SGBD analytique\nParquet : un format de données orienté colonnes\n\n\n\n\n\n\nLe code qui génère les supports est disponible sur GitHub.\n\n\n\nPour approfondir sa connaissance après cette formation d’introduction, rien de tel que la mise en pratique sur des sujets concrets !\n\n\n\n\n\npour toute demande : innovation@insee.fr"
  },
  {
    "objectID": "index.html#contexte",
    "href": "index.html#contexte",
    "title": "Ecosystème data : S3, duckDB, parquet",
    "section": "",
    "text": "Ce site propose un aperçu d’une partie de l’écosystème moderne de traitement de données en abordant 3 technologies :\n\nS3 : le stockage objet\nDuckDB : un SGBD analytique\nParquet : un format de données orienté colonnes"
  },
  {
    "objectID": "index.html#et-après",
    "href": "index.html#et-après",
    "title": "Ecosystème data : S3, duckDB, parquet",
    "section": "",
    "text": "Le code qui génère les supports est disponible sur GitHub.\n\n\n\nPour approfondir sa connaissance après cette formation d’introduction, rien de tel que la mise en pratique sur des sujets concrets !"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Ecosystème data : S3, duckDB, parquet",
    "section": "",
    "text": "pour toute demande : innovation@insee.fr"
  },
  {
    "objectID": "slides/index.html#s3",
    "href": "slides/index.html#s3",
    "title": "Découverte S3",
    "section": "S3",
    "text": "S3"
  },
  {
    "objectID": "source/duckdb/letsgo.html",
    "href": "source/duckdb/letsgo.html",
    "title": "DuckDB, let’s go ! 🦆",
    "section": "",
    "text": "Vous pouvez utiliser DuckDB de plein de manières différentes. Ici on va tout faire en ligne de commande (CLI) mais vous être encouragés à tester les SDK de vos langages préférés !\nDuckDB CLI est distribué sous forme de binaire standalone, téléchargeable directement sur leur site documentaire.\nIl est par ailleurs préinstallé dans la majorité des environnements modernes de datascience dont les environnements lancés par Onyxia\n\n\n\nLancer duckdb :\ngon@laboitemagique:~$ duckdb\nv1.3.0 (Ossivalis) 71c5c07cdd\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nOn constate bien que duckdb travaille uniquement en mémoire (transient in-memory database). Toutes les données seront donc perdues à la fin de la session.\nSi on veut qu’il sauvegarde ses tables, on peut préciser un fichier de database au moment du lancement duckdb madb.db ou à chaud pendant une session : .open madb.db.\n\n\n\nhttps://duckdb.org/docs/stable/sql/introduction.html\n\n\n\nPour configurer la CLI vous avez la possibilité de créer un fichier .duckdbrc à la racine de votre répertoire personnel ($HOME). Ce fichier vous permettra d’exécuter du code au lancement de votre session duckdb.\n.prompt 'duckdb&gt;'\nCREATE OR REPLACE SECRET secret ( TYPE s3, PROVIDER credential_chain, CHAIN \"env;config\", PROFILE 'default',  ENDPOINT \"minio.lab.sspcloud.fr\" );",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#installation",
    "href": "source/duckdb/letsgo.html#installation",
    "title": "DuckDB, let’s go ! 🦆",
    "section": "",
    "text": "Vous pouvez utiliser DuckDB de plein de manières différentes. Ici on va tout faire en ligne de commande (CLI) mais vous être encouragés à tester les SDK de vos langages préférés !\nDuckDB CLI est distribué sous forme de binaire standalone, téléchargeable directement sur leur site documentaire.\nIl est par ailleurs préinstallé dans la majorité des environnements modernes de datascience dont les environnements lancés par Onyxia",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#première-utilisation",
    "href": "source/duckdb/letsgo.html#première-utilisation",
    "title": "DuckDB, let’s go ! 🦆",
    "section": "",
    "text": "Lancer duckdb :\ngon@laboitemagique:~$ duckdb\nv1.3.0 (Ossivalis) 71c5c07cdd\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nOn constate bien que duckdb travaille uniquement en mémoire (transient in-memory database). Toutes les données seront donc perdues à la fin de la session.\nSi on veut qu’il sauvegarde ses tables, on peut préciser un fichier de database au moment du lancement duckdb madb.db ou à chaud pendant une session : .open madb.db.",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#hello-world",
    "href": "source/duckdb/letsgo.html#hello-world",
    "title": "DuckDB, let’s go ! 🦆",
    "section": "",
    "text": "https://duckdb.org/docs/stable/sql/introduction.html",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/duckdb/letsgo.html#optionnel-configuration",
    "href": "source/duckdb/letsgo.html#optionnel-configuration",
    "title": "DuckDB, let’s go ! 🦆",
    "section": "",
    "text": "Pour configurer la CLI vous avez la possibilité de créer un fichier .duckdbrc à la racine de votre répertoire personnel ($HOME). Ce fichier vous permettra d’exécuter du code au lancement de votre session duckdb.\n.prompt 'duckdb&gt;'\nCREATE OR REPLACE SECRET secret ( TYPE s3, PROVIDER credential_chain, CHAIN \"env;config\", PROFILE 'default',  ENDPOINT \"minio.lab.sspcloud.fr\" );",
    "crumbs": [
      "DuckDB",
      "Hello world"
    ]
  },
  {
    "objectID": "source/parquet/cestquoi.html",
    "href": "source/parquet/cestquoi.html",
    "title": "Parquet, c’est quoi ?",
    "section": "",
    "text": "Parquet est un format de fichier orienté colonne développé en 2013 par Cloudera et Twitter en 2013, avant d’être offert à la fondation Apache en 2014 en tant que projet open-source.\nPour bien définir ce qu’est un format de fichier orienté colonne, rappelons d’abord ce qu’est un format de fichier orienté ligne. Dans les formats de fichiers orientés ligne, les données sont enregistrées ligne par ligne ce qui rend le format de fichier optimisé pour les systèmes transactionnels quand il y a besoin de lire ou enregistrer l’intégrité d’un enregistrement.\nPour les formats de fichiers orientés colonne, la donnée est enregistrée par colonne. cela rend le format de fichier très intéressant pour les analyses. Ainsi, pour filtrer l’information sur une colonne précise, il n’y a pas besoin de charger toute une ligne mais seulement la colonne qui nous intéresse selon la requête effectuée, ce qui nous permet d’améliorer les performances. De plus, le format de fichiers orienté colonne permet le vectorized processing: les opérations sont effectuées par lots de valeurs de colonne au lieu de ligne à ligne. Les moteurs d’exécution (DuckDB, Trino, Spark) peuvent ainsi exécuter le même calcul sur des dizaines de valeurs au cours d’un cycle plutôt qu’une ligne à la fois. Enfin, les formats de fichiers orientés colonne sont des formats compressés ce qui permet un gain d’espace.\n\n\nQuelques éléments composant un fichier parquet :\n- row group : partition horizontale des données, chaque groupe contient toutes les colonnes d’un sous-ensemble de lignes. Il s’agit de la plus grande unité de travail.\n- column chunk : colonne au sein d’un row group ce qui permet de réaliser une compression et encodage par colonne.\n- page : plus petite unité de données au sein d’un column chunk.On y retrouve :\n- Data Pages : valeur actuelle\n- Footer : metadatas comme le schema, les row groups, des statistiques…",
    "crumbs": [
      "Parquet",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/parquet/cestquoi.html#composition-dun-fichier-parquet",
    "href": "source/parquet/cestquoi.html#composition-dun-fichier-parquet",
    "title": "Parquet, c’est quoi ?",
    "section": "",
    "text": "Quelques éléments composant un fichier parquet :\n- row group : partition horizontale des données, chaque groupe contient toutes les colonnes d’un sous-ensemble de lignes. Il s’agit de la plus grande unité de travail.\n- column chunk : colonne au sein d’un row group ce qui permet de réaliser une compression et encodage par colonne.\n- page : plus petite unité de données au sein d’un column chunk.On y retrouve :\n- Data Pages : valeur actuelle\n- Footer : metadatas comme le schema, les row groups, des statistiques…",
    "crumbs": [
      "Parquet",
      "C'est quoi ?"
    ]
  },
  {
    "objectID": "source/parquet/memo.html",
    "href": "source/parquet/memo.html",
    "title": "Memo Parquet",
    "section": "",
    "text": "import pandas as pd\nimport s3fs\n\ns3 = s3fs.S3FileSystem()\ndf = pd.read_parquet('my-bucket/my-file.parquet', filesystem=s3, engine='pyarrow')\n\n\n\n\nimport s3fs\nimport pyarrow.parquet as pq\n\ns3 = s3fs.S3FileSystem()\ndf = pq.read_table('my-bucket/my-file.parquet', filesystem=s3)",
    "crumbs": [
      "Parquet",
      "Memo"
    ]
  },
  {
    "objectID": "source/parquet/memo.html#en-utilisant-pandas",
    "href": "source/parquet/memo.html#en-utilisant-pandas",
    "title": "Memo Parquet",
    "section": "",
    "text": "import pandas as pd\nimport s3fs\n\ns3 = s3fs.S3FileSystem()\ndf = pd.read_parquet('my-bucket/my-file.parquet', filesystem=s3, engine='pyarrow')",
    "crumbs": [
      "Parquet",
      "Memo"
    ]
  },
  {
    "objectID": "source/parquet/memo.html#en-utilisant-pyarrow",
    "href": "source/parquet/memo.html#en-utilisant-pyarrow",
    "title": "Memo Parquet",
    "section": "",
    "text": "import s3fs\nimport pyarrow.parquet as pq\n\ns3 = s3fs.S3FileSystem()\ndf = pq.read_table('my-bucket/my-file.parquet', filesystem=s3)",
    "crumbs": [
      "Parquet",
      "Memo"
    ]
  },
  {
    "objectID": "source/s3/letsgo.html",
    "href": "source/s3/letsgo.html",
    "title": "S3, let’s go !",
    "section": "",
    "text": "Il est temps de pratiquer :)\n\n\nVous êtes libres de choisir le serveur S3 auquel vous allez vous connecter.\nVous pouvez même déployer votre propre serveur S3 par exemple en installant minIO\nDans la suite, par simplicité de configuration, on utilisera un service déployé par Onyxia (par exemple sur le SSPCloud).\nLa configuration S3 est alors automatiquement injectée via les variables d’environnement. Le confirmer via env : AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_DEFAULT_REGION, AWS_S3_ENDPOINT.\nSur ces environnements, vous avez les droits sur le bucket du nom de votre identifiant (ou, sur certaines plateformes, à un sous-path d’un bucket) Confirmer qu’on peut bien accéder avec mc ls s3/votreidentifiant\nVous avez aussi, via Onyxia, accès à une interface graphique cliente S3 (onglet mes fichiers)",
    "crumbs": [
      "S3",
      "Let's go !"
    ]
  },
  {
    "objectID": "source/s3/letsgo.html#mise-en-place",
    "href": "source/s3/letsgo.html#mise-en-place",
    "title": "S3, let’s go !",
    "section": "",
    "text": "Vous êtes libres de choisir le serveur S3 auquel vous allez vous connecter.\nVous pouvez même déployer votre propre serveur S3 par exemple en installant minIO\nDans la suite, par simplicité de configuration, on utilisera un service déployé par Onyxia (par exemple sur le SSPCloud).\nLa configuration S3 est alors automatiquement injectée via les variables d’environnement. Le confirmer via env : AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AWS_DEFAULT_REGION, AWS_S3_ENDPOINT.\nSur ces environnements, vous avez les droits sur le bucket du nom de votre identifiant (ou, sur certaines plateformes, à un sous-path d’un bucket) Confirmer qu’on peut bien accéder avec mc ls s3/votreidentifiant\nVous avez aussi, via Onyxia, accès à une interface graphique cliente S3 (onglet mes fichiers)",
    "crumbs": [
      "S3",
      "Let's go !"
    ]
  }
]